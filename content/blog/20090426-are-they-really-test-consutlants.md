title: Consultancy or Agency?
link: http://jaffamonkey.com/2077/are-they-really-test-consutlants
author: jaffamonkey
description: 
post_id: 2077
created: 2009/04/26 12:30:22
created_gmt: 2009/04/26 13:30:22
comment_status: open
post_name: are-they-really-test-consutlants
status: publish
post_type: post

<!--I have slated ISEB numerous times, and the robotic generation of QA it has resulted in.  Our specialism is in taking sound QA  principles, and adapting to environments.    We have done this for many years, and doubt there are many consultants out there with as much modern test experience in our chosen areas of web/media.   We choose Agile as overall approach, but also take parts from other methdologies as seems appropriate.   SCRUM, for example, is more given to projects where all project memebers are dedicated and in same location.-->

# Consultancy or Agency?

I have slated [ISEB](http://www.iseb.org.uk/) numerous times, and the robotic generation of QA it has resulted in.  Our specialism is in taking sound QA  principles, and adapting to environments.    We have done this for many years, and doubt there are many consultants out there with as much modern test experience in our chosen areas of web/media.   We choose Agile as overall approach, but also take parts from other methdologies as seems appropriate.   [SCRUM](http://en.wikipedia.org/wiki/SCRUM target=), for example, is more given to projects where all project members are dedicated and in same location.  As in common with most web projects, budgets are tight on resources.   Testing is generally seen as a necessary luxury, so blundering into a company with no account the company itself, is a short-cut to testing disaster. The majority of test consutlancies, due to their arcfhaic business models, adopt appraoch of expanding test scope as much as ISEB-ly possible - their aim - to get as many people in as possible, to generate the most work. For the unititated, ISEB is a testing qualification, of which the Foundation Level (the easiest entry point) is an exam that comprises of 40 multiple choice questions, and the exam can be taken any number of times.   Consequently it is a professional qualification that can be gained by learning parrot fashion, or taking again and again. The same exam questions appear time and time again, despite assertion by exam board. And these are freely available on forums.  More unfortuinately, agencies and companies starting wanting this qualification as a given.   BBC is one company vastly overpaying for test resources, due to its reliance on qualified but inexperienced testers. Ultimately these by-the-book test consultancies damage overall testing reputation, and likely to cause unecessary delays to projects. Part of why I enjoy QA is the challenge of adapting to projects and companies - the more impossible the odds, the more pleasure I derive from the work. What most QA people forget is to communicate with people - a throwback to older Waterfall projects, where testers were kept in the equivalent of project basement.  To work in reactive and adpative way, communication is key, and that does not mean verbalised QA manure. A recent example from a media company - a test consutlancy was brought in to review a project and they reviewed both project management, development and testing. they (unsurpisingly found it all to be flawed. Of course they didnt have answers beyond more people, and more of their own people of course. Subsequently, they simply spent weeks doing statistics, rehashing existing processes, and spouting ISEB directives like it was a religion. What they failed to do was, well, do anything! In fact the processes were working well, considering restrictions of skills/resoruces, and had been consistently improving, mainly down to the ever improving communication within the porjects. All the consutlancy did was highlight what the company could do nothing about - i.e. work was being done to the best of budget/resources available. Methodologies are supposed to be guidelines not enforced in draconian ways. We know what is important in testing - relationships with project management and development, the key members in a project daily dramas. We are one of a growing number of very independant consutlancies who want to grow, but by building reputation of giving companies what they need, and actively engage with the projects. We move ina small network, who are at the (hate the experession) cutting edge of web project work. It is easy to criticise, but harder to find solutions. A criticsm should always be followed by recommedations and solutions. Otherwise the consutlancy are no better than a heckler. Some resoruces are unavoidable, but most company/project restrictions can be overcome. ![exit](http://blog.jaffamonkey.com/files/2008/08/exit.jpg)Basic Example: It is all theoretically sound to scope for browser compatibility, but nonsensical to expect dedicated time/resource to work on it. The pragmatist solutions - enforce coding standards (responsible for 95% of cross-browser issues). Some testing is task-based and some is role-based, but test consultancies can blur the two, to create illusion of bigger scope. Beware! Test consutlancy isn't a charity, but it should be an unfair tax either.  This is great encapsulation of what the philosophy of a project should be at high-level, from [Creative Chaos](http://xndev.blogspot.com/2009/04/can-we-talk-testing-without-testing.html)

> ... software testing is questioning the product, asking questions like "Is this Good (Enough)?" To do that, you need to answer questions like "What does 'Good Software' mean?" "What does 'Good' mean?" and pretty soon you are asking "What does 'meaning' mean?" The good news is that we can stop wayyyy short of that final question and still declare victory. So we define good according to a value system - for example - we value this over that, because we value this outcome over that outcome -- applied philosophy...